{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF, non_negative_factorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# ---------- using linear least square ----------------\n",
    "def LSTSQDistance(spam, ham, test):\n",
    "    X1 = np.linalg.lstsq(spam, test, rcond = None)[0]\n",
    "    R1 = np.dot(spam, X1)-test\n",
    "    X2 = np.linalg.lstsq(ham, test, rcond = None)[0]\n",
    "    R2 = np.dot(ham, X2)-test\n",
    "    [m, n] = R1.shape\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for i in range(n):\n",
    "        # distance to the spam subspace\n",
    "        d1 = np.linalg.norm(R1[:,i])\n",
    "        # distance to the ham subspace\n",
    "        d2 = np.linalg.norm(R2[:,i])\n",
    "        if d1 >= d2:\n",
    "            # not a spam\n",
    "            neg = neg + 1\n",
    "        else:\n",
    "            # is a spam\n",
    "            pos = pos + 1\n",
    "\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take fold 0 as testing data\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 202 (TP)\t 0 (FP)\n",
      "\n",
      "Predicted as a ham\t 67 (FN)\t 870 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.941\n",
      "Precision =  1.0\n",
      "Recall =  0.751\n",
      "\n",
      "take fold 1 as testing data\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 220 (TP)\t 0 (FP)\n",
      "\n",
      "Predicted as a ham\t 68 (FN)\t 877 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.942\n",
      "Precision =  1.0\n",
      "Recall =  0.764\n",
      "\n",
      "take fold 2 as testing data\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 199 (TP)\t 1 (FP)\n",
      "\n",
      "Predicted as a ham\t 70 (FN)\t 877 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.938\n",
      "Precision =  0.995\n",
      "Recall =  0.74\n",
      "\n",
      "take fold 3 as testing data\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 194 (TP)\t 0 (FP)\n",
      "\n",
      "Predicted as a ham\t 71 (FN)\t 871 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.938\n",
      "Precision =  1.0\n",
      "Recall =  0.732\n",
      "\n",
      "take fold 4 as testing data\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 209 (TP)\t 1 (FP)\n",
      "\n",
      "Predicted as a ham\t 73 (FN)\t 861 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.935\n",
      "Precision =  0.995\n",
      "Recall =  0.741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. use different folds--------------------\n",
    "emails = pd.read_csv(\"emails.csv\", encoding= 'unicode_escape')\n",
    "df = pd.DataFrame(emails)\n",
    "spam = df['spam']\n",
    "flod = df['fold']\n",
    "\n",
    "# initialize\n",
    "cv = TfidfVectorizer(stop_words='english', max_features=20000, token_pattern=r\"(?u)\\b[a-zA-Z]\\w+\\b\") \n",
    "dt_matrix = cv.fit_transform(df['text']) \n",
    "[m, n] = dt_matrix.shape\n",
    "\n",
    "# For each email, we have two tags: spam and fold.\n",
    "# Spam = 1 means the email is a spam; spam = 0 means the email is not a spam\n",
    "# And for each email, it also belongs to a fold.\n",
    "# In this file, there are 5 fold, numbered from 0 to 4.\n",
    "# In this example, we will use fold 0-3 as training data and fold 4 as test data.\n",
    "\n",
    "for t in range(0,5):\n",
    "    \n",
    "    print(\"take fold\", t, \"as testing data\")\n",
    "\n",
    "    spam_train = (dt_matrix[[i for i in range(m) if flod[i]!=t and spam[i]==1], :]).toarray().transpose()\n",
    "    spam_test  = (dt_matrix[[i for i in range(m) if flod[i]==t and spam[i]==1], :]).toarray().transpose()\n",
    "    ham_train = (dt_matrix[[i for i in range(m) if flod[i]!=t and spam[i]==0], :]).toarray().transpose()\n",
    "    ham_test  = (dt_matrix[[i for i in range(m) if flod[i]==t and spam[i]==0], :]).toarray().transpose()\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    tp, fn = LSTSQDistance(spam_train, ham_train, spam_test)\n",
    "    fp, tn = LSTSQDistance(spam_train, ham_train, ham_test)\n",
    "\n",
    "    N = len(spam_test[0]) + len(ham_test[0])\n",
    "    #print(N, \" \" , tp+tn)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\\t\\t\\tIs a spam\\tIs a ham\")\n",
    "    print(\"Predicted as a spam\\t\", tp, \"(TP)\\t\", fp, \"(FP)\")\n",
    "    print(\"\\nPredicted as a ham\\t\", fn, \"(FN)\\t\", tn, \"(TN)\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Accuracy = \" , round((tp+tn) / N, 3))\n",
    "    print(\"Precision = \" , round((tp)/(tp + fp), 3))\n",
    "    print(\"Recall = \" , round((tp)/(tp + fn), 3))\n",
    "    print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take fold 4 as testing data and doing SVD decomposition\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 209 (TP)\t 1 (FP)\n",
      "\n",
      "Predicted as a ham\t 73 (FN)\t 861 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.935\n",
      "Precision =  0.995\n",
      "Recall =  0.741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. SVD decomposition --------------------\n",
    "emails = pd.read_csv(\"emails.csv\", encoding= 'unicode_escape')\n",
    "df = pd.DataFrame(emails)\n",
    "spam = df['spam']\n",
    "flod = df['fold']\n",
    "\n",
    "# initialize\n",
    "cv = TfidfVectorizer(stop_words='english', max_features=20000, token_pattern=r\"(?u)\\b[a-zA-Z]\\w+\\b\") \n",
    "dt_matrix = cv.fit_transform(df['text']) \n",
    "[m, n] = dt_matrix.shape\n",
    "\n",
    "# For each email, we have two tags: spam and fold.\n",
    "# Spam = 1 means the email is a spam; spam = 0 means the email is not a spam\n",
    "# And for each email, it also belongs to a fold.\n",
    "# In this file, there are 5 fold, numbered from 0 to 4.\n",
    "# In this example, we will use fold 0-3 as training data and fold 4 as test data.\n",
    "\n",
    "t = 4 # 0, 1, 2, 3, 4\n",
    "    \n",
    "print(\"take fold\", t, \"as testing data and doing SVD decomposition\")\n",
    "\n",
    "spam_train = (dt_matrix[[i for i in range(m) if flod[i]!=t and spam[i]==1], :]).toarray().transpose()\n",
    "spam_test  = (dt_matrix[[i for i in range(m) if flod[i]==t and spam[i]==1], :]).toarray().transpose()\n",
    "ham_train = (dt_matrix[[i for i in range(m) if flod[i]!=t and spam[i]==0], :]).toarray().transpose()\n",
    "ham_test  = (dt_matrix[[i for i in range(m) if flod[i]==t and spam[i]==0], :]).toarray().transpose()\n",
    "\n",
    "spam_U, spam_sigma, spam_vt = np.linalg.svd(spam_train)\n",
    "ham_U, ham_sigma, ham_vt = np.linalg.svd(ham_train)\n",
    "\n",
    "s_rank = np.linalg.matrix_rank(spam_train)\n",
    "spam_new = spam_U[:, :s_rank]\n",
    "\n",
    "h_rank = np.linalg.matrix_rank(ham_train)\n",
    "ham_new = ham_U[:, :h_rank]\n",
    "\n",
    "\n",
    "# Compute the confusion matrix\n",
    "tp, fn = LSTSQDistance(spam_new, ham_new, spam_test)\n",
    "fp, tn = LSTSQDistance(spam_new, ham_new, ham_test)\n",
    "\n",
    "N = len(spam_test[0]) + len(ham_test[0])\n",
    "#print(N, \" \" , tp+tn)\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"\\t\\t\\tIs a spam\\tIs a ham\")\n",
    "print(\"Predicted as a spam\\t\", tp, \"(TP)\\t\", fp, \"(FP)\")\n",
    "print(\"\\nPredicted as a ham\\t\", fn, \"(FN)\\t\", tn, \"(TN)\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Accuracy = \" , round((tp+tn) / N, 3))\n",
    "print(\"Precision = \" , round((tp)/(tp + fp), 3))\n",
    "print(\"Recall = \" , round((tp)/(tp + fn), 3))\n",
    "print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"emails.csv\", encoding= 'unicode_escape')\n",
    "df = pd.DataFrame(emails)\n",
    "spam = df['spam']\n",
    "flod = df['fold']\n",
    "\n",
    "# initialize\n",
    "cv = TfidfVectorizer(stop_words='english', max_features=20000, token_pattern=r\"(?u)\\b[a-zA-Z]\\w+\\b\") \n",
    "dt_matrix = cv.fit_transform(df['text']) \n",
    "[m, n] = dt_matrix.shape\n",
    "spam_train = (dt_matrix[[i for i in range(m) if flod[i]!=4 and spam[i]==1], :]).toarray().transpose()\n",
    "spam_test  = (dt_matrix[[i for i in range(m) if flod[i]==4 and spam[i]==1], :]).toarray().transpose()\n",
    "ham_train = (dt_matrix[[i for i in range(m) if flod[i]!=4 and spam[i]==0], :]).toarray().transpose()\n",
    "ham_test  = (dt_matrix[[i for i in range(m) if flod[i]==4 and spam[i]==0], :]).toarray().transpose()\n",
    "\n",
    "spam_U, spam_sigma, spam_vt = np.linalg.svd(spam_train)\n",
    "ham_U, ham_sigma, ham_vt = np.linalg.svd(ham_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3336\n",
      "3496\n"
     ]
    }
   ],
   "source": [
    "h_rank = np.linalg.matrix_rank(ham_train)\n",
    "ham_new = ham_U[:, :h_rank]\n",
    "print(h_rank)\n",
    "print(len(ham_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032\n",
      "1091\n"
     ]
    }
   ],
   "source": [
    "s_rank = np.linalg.matrix_rank(spam_train)\n",
    "spam_new = spam_U[:, :s_rank]\n",
    "print(s_rank)\n",
    "print(len(spam_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 255 fn= 27\n",
      "fp= 1 tn= 861\n",
      "\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 255 (TP)\t 1 (FP)\n",
      "\n",
      "Predicted as a ham\t 27 (FN)\t 861 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.976\n",
      "Precision =  0.996\n",
      "Recall =  0.904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. LSA Try different low rank approximation using SVD for S and H------------------------------------------------\n",
    "emails = pd.read_csv(\"emails.csv\", encoding= 'unicode_escape')\n",
    "df = pd.DataFrame(emails)\n",
    "spam = df['spam']\n",
    "flod = df['fold']\n",
    "\n",
    "# initialize\n",
    "cv = TfidfVectorizer(stop_words='english', max_features=20000, token_pattern=r\"(?u)\\b[a-zA-Z]\\w+\\b\") \n",
    "dt_matrix = cv.fit_transform(df['text']) \n",
    "[m, n] = dt_matrix.shape\n",
    "spam_train = (dt_matrix[[i for i in range(m) if flod[i]!=4 and spam[i]==1], :]).toarray().transpose()\n",
    "spam_test  = (dt_matrix[[i for i in range(m) if flod[i]==4 and spam[i]==1], :]).toarray().transpose()\n",
    "ham_train = (dt_matrix[[i for i in range(m) if flod[i]!=4 and spam[i]==0], :]).toarray().transpose()\n",
    "ham_test  = (dt_matrix[[i for i in range(m) if flod[i]==4 and spam[i]==0], :]).toarray().transpose()\n",
    "\n",
    "h_rank = 600 #200, 200, 100\n",
    "s_rank = 200 #600, 200, 600\n",
    "spam_U, spam_sigma, spam_vt = np.linalg.svd(spam_train)\n",
    "ham_U, ham_sigma, ham_vt = np.linalg.svd(ham_train)\n",
    "ham_new = ham_U[:, :h_rank]\n",
    "spam_new = spam_U[:, :s_rank]\n",
    "tp, fn = LSTSQDistance(spam_new, ham_new, spam_test)\n",
    "fp, tn = LSTSQDistance(spam_new, ham_new, ham_test)\n",
    "print(\"tp=\",tp, \"fn=\",fn)\n",
    "print(\"fp=\",fp, \"tn=\",tn)\n",
    "print()\n",
    "N = len(spam_test[0]) + len(ham_test[0])\n",
    "#print(N, \" \" , tp+tn)\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"\\t\\t\\tIs a spam\\tIs a ham\")\n",
    "print(\"Predicted as a spam\\t\", tp, \"(TP)\\t\", fp, \"(FP)\")\n",
    "print(\"\\nPredicted as a ham\\t\", fn, \"(FN)\\t\", tn, \"(TN)\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Accuracy = \" , round((tp+tn) / N, 3))\n",
    "print(\"Precision = \" , round((tp)/(tp + fp), 3))\n",
    "print(\"Recall = \" , round((tp)/(tp + fn), 3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 281 fn= 1\n",
      "fp= 104 tn= 758\n",
      "\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 281 (TP)\t 104 (FP)\n",
      "\n",
      "Predicted as a ham\t 1 (FN)\t\t 758 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.908\n",
      "Precision =  0.73\n",
      "Recall =  0.996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h_rank = 100 #200, 200, 100\n",
    "s_rank = 600 #600, 200, 600\n",
    "ham_new = ham_U[:, :h_rank]\n",
    "spam_new = spam_U[:, :s_rank]\n",
    "tp, fn = LSTSQDistance(spam_new, ham_new, spam_test)\n",
    "fp, tn = LSTSQDistance(spam_new, ham_new, ham_test)\n",
    "print(\"tp=\",tp, \"fn=\",fn)\n",
    "print(\"fp=\",fp, \"tn=\",tn)\n",
    "print()\n",
    "N = len(spam_test[0]) + len(ham_test[0])\n",
    "#print(N, \" \" , tp+tn)\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"\\t\\t\\tIs a spam\\tIs a ham\")\n",
    "print(\"Predicted as a spam\\t\", tp, \"(TP)\\t\", fp, \"(FP)\")\n",
    "print(\"\\nPredicted as a ham\\t\", fn, \"(FN)\\t\\t\", tn, \"(TN)\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Accuracy = \" , round((tp+tn) / N, 3))\n",
    "print(\"Precision = \" , round((tp)/(tp + fp), 3))\n",
    "print(\"Recall = \" , round((tp)/(tp + fn), 3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take fold 0 as testing data and doing NMF decomposition\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 265 (TP)\t 11 (FP)\n",
      "\n",
      "Predicted as a ham\t 4 (FN)\t\t 859 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.987\n",
      "Precision =  0.96\n",
      "Recall =  0.985\n",
      "\n",
      "take fold 1 as testing data and doing NMF decomposition\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 278 (TP)\t 26 (FP)\n",
      "\n",
      "Predicted as a ham\t 10 (FN)\t\t 851 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.969\n",
      "Precision =  0.914\n",
      "Recall =  0.965\n",
      "\n",
      "take fold 2 as testing data and doing NMF decomposition\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 261 (TP)\t 17 (FP)\n",
      "\n",
      "Predicted as a ham\t 8 (FN)\t\t 861 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.978\n",
      "Precision =  0.939\n",
      "Recall =  0.97\n",
      "\n",
      "take fold 3 as testing data and doing NMF decomposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANA\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 263 (TP)\t 37 (FP)\n",
      "\n",
      "Predicted as a ham\t 2 (FN)\t\t 834 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.966\n",
      "Precision =  0.877\n",
      "Recall =  0.992\n",
      "\n",
      "take fold 4 as testing data and doing NMF decomposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANA\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 275 (TP)\t 19 (FP)\n",
      "\n",
      "Predicted as a ham\t 7 (FN)\t\t 843 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.977\n",
      "Precision =  0.935\n",
      "Recall =  0.975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. use NMF decomposition --------------------\n",
    "emails = pd.read_csv(\"emails.csv\", encoding= 'unicode_escape')\n",
    "df = pd.DataFrame(emails)\n",
    "spam = df['spam']\n",
    "flod = df['fold']\n",
    "\n",
    "# initialize\n",
    "cv = TfidfVectorizer(stop_words='english', max_features=20000, token_pattern=r\"(?u)\\b[a-zA-Z]\\w+\\b\") \n",
    "dt_matrix = cv.fit_transform(df['text']) \n",
    "[m, n] = dt_matrix.shape\n",
    "\n",
    "# For each email, we have two tags: spam and fold.\n",
    "# Spam = 1 means the email is a spam; spam = 0 means the email is not a spam\n",
    "# And for each email, it also belongs to a fold.\n",
    "# In this file, there are 5 fold, numbered from 0 to 4.\n",
    "# In this example, we will use fold 0-3 as training data and fold 4 as test data.\n",
    "\n",
    "for t in range(0,5):\n",
    "    \n",
    "    print(\"take fold\", t, \"as testing data and doing NMF decomposition\")\n",
    "\n",
    "    spam_train = (dt_matrix[[i for i in range(m) if flod[i]!=t and spam[i]==1], :]).toarray().transpose()\n",
    "    spam_test  = (dt_matrix[[i for i in range(m) if flod[i]==t and spam[i]==1], :]).toarray().transpose()\n",
    "    ham_train = (dt_matrix[[i for i in range(m) if flod[i]!=t and spam[i]==0], :]).toarray().transpose()\n",
    "    ham_test  = (dt_matrix[[i for i in range(m) if flod[i]==t and spam[i]==0], :]).toarray().transpose()\n",
    "    \n",
    "    s_W, s_H, s_n_iter = non_negative_factorization(spam_train, n_components=100, init='random', random_state=0)\n",
    "    h_W, h_H, h_n_iter = non_negative_factorization(ham_train, n_components=100, init='random', random_state=0)\n",
    "\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    tp, fn = LSTSQDistance(s_W, h_W, spam_test)\n",
    "    fp, tn = LSTSQDistance(s_W, h_W, ham_test)\n",
    "\n",
    "    N = len(spam_test[0]) + len(ham_test[0])\n",
    "    #print(N, \" \" , tp+tn)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\\t\\t\\tIs a spam\\tIs a ham\")\n",
    "    print(\"Predicted as a spam\\t\", tp, \"(TP)\\t\", fp, \"(FP)\")\n",
    "    print(\"\\nPredicted as a ham\\t\", fn, \"(FN)\\t\\t\", tn, \"(TN)\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Accuracy = \" , round((tp+tn) / N, 3))\n",
    "    print(\"Precision = \" , round((tp)/(tp + fp), 3))\n",
    "    print(\"Recall = \" , round((tp)/(tp + fn), 3))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091\n",
      "20000\n",
      "3496\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(spam_train[1])) # 1091 筆資料  20000 個 term\n",
    "print(len(spam_train))\n",
    "\n",
    "print(len(ham_train[1]))# 3496 筆資料  20000 個 term\n",
    "print(len(ham_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spam_U, spam_sigma, spam_vt = np.linalg.svd(spam_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.60208116e-04  2.75916139e-04 -2.48116643e-04 ...  4.23653853e-05\n",
      "   0.00000000e+00  3.02419073e-05]\n",
      " [ 2.49502025e-17 -1.24615487e-17  8.63634793e-18 ... -1.55085105e-04\n",
      "   0.00000000e+00 -2.62581413e-03]\n",
      " [ 1.01643954e-17 -8.14845695e-18  4.73999637e-18 ...  5.22148727e-04\n",
      "   0.00000000e+00 -2.27343755e-04]\n",
      " ...\n",
      " [-1.92112741e-03  2.49278188e-03 -2.67662716e-03 ...  8.65656584e-01\n",
      "   0.00000000e+00 -1.18697607e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00]\n",
      " [-2.59008585e-03  1.39807412e-03 -1.28690724e-03 ... -1.27844699e-03\n",
      "   0.00000000e+00  6.81510685e-01]]\n",
      "20000\n",
      "20000\n",
      "(20000, 20000)\n"
     ]
    }
   ],
   "source": [
    "print(spam_U)\n",
    "print(len(spam_U))\n",
    "print(len(spam_U[0]))\n",
    "print(spam_U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.09537426e+00 5.21277509e+00 4.82273242e+00 ... 2.50009141e-16\n",
      " 2.44853169e-16 1.91687379e-16]\n",
      "1087\n",
      "20000\n",
      "[[6.09537426 0.        ]\n",
      " [0.         5.21277509]\n",
      " [0.         0.        ]\n",
      " ...\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "1.916873790483511e-16\n"
     ]
    }
   ],
   "source": [
    "print(spam_sigma)\n",
    "print(len(spam_sigma))\n",
    "k = np.pad(spam_sigma, (0,20000-len(spam_sigma)), mode = 'constant')\n",
    "\n",
    "print(len(k))\n",
    "\n",
    "spam_new = np.diag(k)\n",
    "print(spam_new[:,0:2])\n",
    "print(spam_sigma[1086])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_U, ham_sigma, ham_vt = np.linalg.svd(ham_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.88990011e-03  7.33286204e-04 -5.34759903e-03 ...  0.00000000e+00\n",
      "  -1.19270964e-04  0.00000000e+00]\n",
      " [ 6.24185292e-04 -3.24674226e-04 -1.52483019e-04 ...  0.00000000e+00\n",
      "  -4.06435105e-05  0.00000000e+00]\n",
      " [ 3.66213508e-04  1.09030773e-03  6.63871666e-04 ...  0.00000000e+00\n",
      "   2.59193786e-04  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 5.37650772e-05  1.23554667e-04 -2.40157510e-05 ...  0.00000000e+00\n",
      "   9.84906727e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]]\n",
      "20000\n",
      "20000\n",
      "(20000, 20000)\n"
     ]
    }
   ],
   "source": [
    "print(ham_U)\n",
    "print(len(ham_U))\n",
    "print(len(ham_U[0]))\n",
    "print(ham_U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.20562173e+01 7.08860748e+00 5.31320601e+00 ... 7.21198736e-16\n",
      " 3.47141150e-16 2.70496958e-16]\n",
      "3496\n",
      "20000\n",
      "[[12.05621729  0.          0.          0.        ]\n",
      " [ 0.          7.08860748  0.          0.        ]\n",
      " [ 0.          0.          5.31320601  0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(ham_sigma)\n",
    "print(len(ham_sigma))\n",
    "l = np.pad(ham_sigma, (0,20000-len(ham_sigma)), mode = 'constant')\n",
    "\n",
    "print(len(l))\n",
    "\n",
    "ham_new = np.diag(l)\n",
    "print(ham_new[:,0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 208 fn= 73\n",
      "fp= 1 tn= 861\n"
     ]
    }
   ],
   "source": [
    "tp, fn = LSTSQDistance(spam_new, ham_new, spam_test)\n",
    "fp, tn = LSTSQDistance(spam_new, ham_new, ham_test)\n",
    "\n",
    "print(\"tp=\",tp, \"fn=\",fn)\n",
    "print(\"fp=\",fp, \"tn=\",tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"emails.csv\")\n",
    "df = pd.DataFrame(emails)\n",
    "spam = df['spam']\n",
    "flod = df['fold']\n",
    "\n",
    "# initialize\n",
    "cv = TfidfVectorizer(stop_words='english', max_features=20000, token_pattern=r\"(?u)\\b[a-zA-Z]\\w+\\b\") \n",
    "dt_matrix = cv.fit_transform(df['text']) \n",
    "[m, n] = dt_matrix.shape\n",
    "spam_train = (dt_matrix[[i for i in range(m) if flod[i]!=4 and spam[i]==1], :]).toarray().transpose()\n",
    "spam_test  = (dt_matrix[[i for i in range(m) if flod[i]==4 and spam[i]==1], :]).toarray().transpose()\n",
    "ham_train = (dt_matrix[[i for i in range(m) if flod[i]!=4 and spam[i]==0], :]).toarray().transpose()\n",
    "ham_test  = (dt_matrix[[i for i in range(m) if flod[i]==4 and spam[i]==0], :]).toarray().transpose()\n",
    "#spam_U, spam_sigma, spam_vt = np.linalg.svd(spam_train)\n",
    "#ham_U, ham_sigma, ham_vt = np.linalg.svd(ham_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_W, s_H, s_n_iter = non_negative_factorization(spam_train, n_components=100, init='random', random_state=0)\n",
    "h_W, h_H, h_n_iter = non_negative_factorization(ham_train, n_components=100, init='random', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n",
      "(100, 1087)\n",
      "(20000, 100)\n",
      "(100, 3496)\n"
     ]
    }
   ],
   "source": [
    "print(s_W.shape)\n",
    "print(s_H.shape)\n",
    "print(h_W.shape)\n",
    "print(h_H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 275 fn= 6\n",
      "fp= 20 tn= 842\n",
      "\n",
      "--------------------------------------------------\n",
      "\t\t\tIs a spam\tIs a ham\n",
      "Predicted as a spam\t 275 (TP)\t 20 (FP)\n",
      "\n",
      "Predicted as a ham\t 6 (FN)\t 842 (TN)\n",
      "--------------------------------------------------\n",
      "Accuracy =  0.977\n",
      "Precision =  0.932\n",
      "Recall =  0.979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fn = LSTSQDistance(s_W, h_W, spam_test)\n",
    "fp, tn = LSTSQDistance(s_W, h_W, ham_test)\n",
    "print(\"tp=\",tp, \"fn=\",fn)\n",
    "print(\"fp=\",fp, \"tn=\",tn)\n",
    "print()\n",
    "N = len(spam_test[0]) + len(ham_test[0])\n",
    "#print(N, \" \" , tp+tn)\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"\\t\\t\\tIs a spam\\tIs a ham\")\n",
    "print(\"Predicted as a spam\\t\", tp, \"(TP)\\t\", fp, \"(FP)\")\n",
    "print(\"\\nPredicted as a ham\\t\", fn, \"(FN)\\t\\t\", tn, \"(TN)\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Accuracy = \" , round((tp+tn) / N, 3))\n",
    "print(\"Precision = \" , round((tp)/(tp + fp), 3))\n",
    "print(\"Recall = \" , round((tp)/(tp + fn), 3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
